{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "670d677b",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 08:57:30.142162: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f455f992",
   "metadata": {},
   "source": [
    "kaggle datasets download -d mirzaniazmorshed/ntsb-aviation-accidents\n",
    "unzip ntsb-aviation-accidents.zip -d ntsb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86645b4",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "broad_cause\n",
       "Personnel issues         24358\n",
       "Aircraft                 21886\n",
       "Environmental issues     11838\n",
       "Not determined            2134\n",
       "Organizational issues      709\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_narr = pd.read_excel('ntsb_data/narratives.xlsx')\n",
    "df_find = pd.read_excel('ntsb_data/Findings_merged.xlsx')\n",
    "df_joined = pd.merge(df_narr, df_find, on='ev_id', how='inner')\n",
    "df = df_joined[['narr_accp', 'finding_description']].dropna()\n",
    "\n",
    "df['broad_cause'] = df['finding_description'].str.split('-').str[0]\n",
    "df = df[df.groupby('broad_cause')['broad_cause'].transform('count') > 50]\n",
    "df['broad_cause'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1de3df8",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Personnel issues-Action/decision-Info processi...\n",
       "1        Personnel issues-Action/decision-Info processi...\n",
       "2        Personnel issues-Action/decision-Info processi...\n",
       "3        Personnel issues-Action/decision-Info processi...\n",
       "4        Environmental issues-Conditions/weather/phenom...\n",
       "                               ...                        \n",
       "67039    Personnel issues-Psychological-Perception/orie...\n",
       "67055    Aircraft-Aircraft systems-Electrical power sys...\n",
       "67056    Personnel issues-Task performance-Maintenance-...\n",
       "67060    Aircraft-Aircraft oper/perf/capability-Perform...\n",
       "67061    Aircraft-Aircraft structures-Empennage structu...\n",
       "Name: finding_description, Length: 58082, dtype: str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['finding_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b121ddc",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal sequence length (95th percentile): 667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1770364713.724524    6393 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21764 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:2b:00.0, compute capability: 8.6\n",
      "2026-02-06 08:58:39.042922: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 1081598880 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 08:58:51.016375: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 0.3947 - loss: 1.0508\n",
      "Epoch 2/15\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - accuracy: 0.4420 - loss: 0.9889\n",
      "Epoch 3/15\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - accuracy: 0.4504 - loss: 0.9579\n",
      "Epoch 4/15\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.4623 - loss: 0.9312\n",
      "Epoch 5/15\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.4627 - loss: 0.9072\n",
      "Epoch 6/15\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - accuracy: 0.4683 - loss: 0.8871\n",
      "Epoch 7/15\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.4744 - loss: 0.8745\n",
      "Epoch 8/15\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - accuracy: 0.4811 - loss: 0.8603\n",
      "Epoch 9/15\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - accuracy: 0.4834 - loss: 0.8520\n",
      "Epoch 10/15\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - accuracy: 0.4870 - loss: 0.8424\n",
      "Epoch 11/15\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 20ms/step - accuracy: 0.4911 - loss: 0.8353\n",
      "Epoch 12/15\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 20ms/step - accuracy: 0.4929 - loss: 0.8275\n",
      "Epoch 13/15\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.4947 - loss: 0.8226\n",
      "Epoch 14/15\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 20ms/step - accuracy: 0.4984 - loss: 0.8158\n",
      "Epoch 15/15\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 20ms/step - accuracy: 0.5001 - loss: 0.8090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x796629530ce0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "class_counts = df['broad_cause'].value_counts()\n",
    "valid_classes = class_counts[class_counts > 3000].index\n",
    "df = df[df['broad_cause'].isin(valid_classes)].copy()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['label_int'] = encoder.fit_transform(df['broad_cause'])\n",
    "num_classes = len(encoder.classes_)\n",
    "\n",
    "\n",
    "doc_lens = df['narr_accp'].astype(str).apply(lambda x: len(x.split()))\n",
    "sequence_length = int(np.percentile(doc_lens, 95))\n",
    "print(f\"Optimal sequence length (95th percentile): {sequence_length}\")\n",
    "\n",
    "\n",
    "max_tokens = 15000  # Increased for the 3090\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length,\n",
    "    ngrams=(1, 2) # Captures bigrams like \"engine_failure\" or \"pilot_error\"\n",
    ")\n",
    "vectorize_layer.adapt(df['narr_accp'].values)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
    "    vectorize_layer,\n",
    "    layers.Embedding(input_dim=max_tokens, output_dim=128, mask_zero=False),\n",
    "    \n",
    "    # Convolutional block: Looks for \"phrases\" of 5 tokens\n",
    "    layers.Conv1D(128, 5, activation='relu', padding='same'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    \n",
    "    # Deeper block for more abstract features\n",
    "    layers.Conv1D(256, 5, activation='relu', padding='same'),\n",
    "    layers.GlobalMaxPooling1D(), # Picks the most descriptive \"feature\" found\n",
    "    \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5), # Essential to prevent over-memorizing technical templates\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "train_x = df['narr_accp'].values.astype(str)\n",
    "train_y = df['label_int'].values.astype('int32')\n",
    "\n",
    "weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_y), y=train_y)\n",
    "class_weight_dict = dict(enumerate(weights))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "dataset = dataset.shuffle(5000).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(dataset, epochs=15, class_weight=class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0c7e4f",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
